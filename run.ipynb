{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to wiki xml file: ^C\n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "!python src/WikiSplitter.py split-wiki dump.xml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U pip setuptools wheel\n",
    "%pip install -U spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!node parseWikitext.js\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_pageviews(session, article, year):\n",
    "    base_url = \"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article\"\n",
    "    domain = \"en.wikipedia.org\"\n",
    "    access = \"all-access\"\n",
    "    agent = \"user\"\n",
    "\n",
    "    start_date = f\"{year}0101\"\n",
    "    end_date = f\"{year}1231\"\n",
    "\n",
    "    url = f\"{base_url}/{domain}/{access}/{agent}/{article}/monthly/{start_date}/{end_date}\"\n",
    "\n",
    "    async with session.get(url) as response:\n",
    "        if response.status == 200:\n",
    "            data = await response.json()\n",
    "            return article, data\n",
    "        else:\n",
    "            return article, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_articles(articles_titles, year):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for article_title in articles_titles:\n",
    "            task = asyncio.ensure_future(\n",
    "                fetch_pageviews(session, article_title, year))\n",
    "            tasks.append(task)\n",
    "\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        for article, data in responses:\n",
    "            if data:\n",
    "                total_views = sum(item['views'] for item in data['items'])\n",
    "                print(\n",
    "                    f\"Total Pageviews for {article} in {year}: {total_views}\")\n",
    "            else:\n",
    "                print(f\"Failed to retrieve data for {article}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_articles_from_json(folder_path, processed_files, max_articles=500):\n",
    "    articles = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if len(articles) >= max_articles:\n",
    "            return articles, processed_files\n",
    "        if filename.endswith('.json') and filename not in processed_files:\n",
    "            with open(os.path.join(folder_path, filename)) as f:\n",
    "                articles = json.load(f)\n",
    "                for article in articles:\n",
    "                    articles.append(article)    \n",
    "                processed_files.add(filename)\n",
    "            processed_files.add(filename)\n",
    "    return articles, processed_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_pageviews_for_articles(folder_path=\"./2_wikitext_parser_output/\",  year=\"2023\",    processed_files_path='./processed_files.txt', files_at_once=6):\n",
    "\n",
    "    # Lade die Namen der bereits verarbeiteten Dateien\n",
    "    if os.path.exists(processed_files_path):\n",
    "        with open(processed_files_path, 'r') as f:\n",
    "            processed_files = set(f.read().splitlines())\n",
    "    else:\n",
    "        processed_files = set()\n",
    "\n",
    "    while True:\n",
    "        articles, processed_files = load_articles_from_json(\n",
    "            folder_path, processed_files, max_articles=200)\n",
    "        print(len(articles))\n",
    "        break\n",
    "        if not articles:\n",
    "            break  # Beendet die Schleife, wenn keine Artikel mehr zu verarbeiten sind\n",
    "\n",
    "        await process_articles(articles, year)\n",
    "\n",
    "        # Aktualisiere die Liste der verarbeiteten Dateien\n",
    "        with open(processed_files_path, 'w') as f:\n",
    "            for file in processed_files:\n",
    "                f.write(file + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    }
   ],
   "source": [
    "await fetch_pageviews_for_articles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parsed_articles.json') as file:\n",
    "    parsed_articles = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string: str):\n",
    "  return string.replace(\n",
    "                '\\n', ' ').replace('  ', ' ').strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "for article in parsed_articles:\n",
    "    doc = nlp(article['history'])\n",
    "    sentences = list(doc.sents)\n",
    "    sentences_with_dates = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"DATE\":\n",
    "            current_sentence = ent.sent\n",
    "            current_index = sentences.index(current_sentence)\n",
    "            current_sentence_text = clean_str(current_sentence.text)\n",
    "\n",
    "            # Hinzufügen des vorherigen Satzes, wenn vorhanden und noch nicht in der Liste\n",
    "            # if current_index > 0 and sentences[current_index - 1].text not in sentences_with_dates:\n",
    "                # sentences_with_dates.append(sentences[current_index - 1].text)\n",
    "\n",
    "            # Hinzufügen des aktuellen Satzes, wenn noch nicht in der Liste\n",
    "            if current_sentence_text not in sentences_with_dates:\n",
    "                sentences_with_dates.append(current_sentence_text)\n",
    "\n",
    "            # Hinzufügen des nachfolgenden Satzes, wenn vorhanden und noch nicht in der Liste\n",
    "            # if current_index < len(sentences) - 1 and sentences[current_index + 1].text not in sentences_with_dates:\n",
    "                # sentences_with_dates.append(sentences[current_index + 1].text)\n",
    "        \n",
    "    article['sentencesWithDates'] = ' '.join(sentences_with_dates)\n",
    "    articles.append(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def remove_first_parentheses_in_first_sentence(text):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text, maxsplit=1)\n",
    "    first_sentence = sentences[0]\n",
    "    remaining_text = sentences[1] if len(sentences) > 1 else ''\n",
    "    cleaned_first_sentence = re.sub(r'\\(.*?\\)', '', first_sentence, count=1)\n",
    "    return cleaned_first_sentence + ' ' + remaining_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_articles = []\n",
    "for article in articles:\n",
    "    if article['sentencesWithDates'] == '':\n",
    "        continue\n",
    "    if 'shortDescription' in article:\n",
    "        article['shortDescription'] = remove_first_parentheses_in_first_sentence(\n",
    "            article['shortDescription'])\n",
    "    if 'description' in article:\n",
    "        article['description'] = remove_first_parentheses_in_first_sentence(\n",
    "            article['description'])\n",
    "    if article['sentencesWithDates'] == '':\n",
    "        continue\n",
    "    cleaned_articles.append(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_wikipedia_pageviews_2022(title):\n",
    "    \"\"\"\n",
    "    Ermittelt die Gesamtzahl der Seitenaufrufe für einen Wikipedia-Artikel im Jahr 2022.\n",
    "    \n",
    "    :param title: Titel des Wikipedia-Artikels.\n",
    "    :return: Anzahl der Seitenaufrufe oder eine Fehlermeldung.\n",
    "    \"\"\"\n",
    "    # URL für die Wikipedia API, die Seitenaufrufe für das Jahr 2022 abruft\n",
    "    url = f\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia/all-access/user/{title}/daily/2022010100/2022123100\"\n",
    "\n",
    "    try:\n",
    "        headers = {\n",
    "          'User-Agent': 'MeinPythonSkript/1.0 (meineemail@example.com)'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        total_views = sum(item['views'] for item in data['items'])\n",
    "        return total_views\n",
    "    except requests.RequestException as e:\n",
    "        return f\"Fehler bei der Anfrage: {e}\"\n",
    "    except KeyError:\n",
    "        return \"Fehler bei der Verarbeitung der Daten.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seitenaufrufe für Alberta: 1020808\n",
      "Seitenaufrufe für Ankara: 640512\n",
      "Seitenaufrufe für Aberdeenshire: 198238\n",
      "Seitenaufrufe für Azincourt: 41905\n",
      "Seitenaufrufe für Achill Island: 102543\n",
      "Seitenaufrufe für Anguilla: 529462\n",
      "Seitenaufrufe für Ashmore and Cartier Islands: 72160\n",
      "Seitenaufrufe für Ames, Iowa: 169544\n",
      "Seitenaufrufe für Abensberg: 5275\n",
      "Seitenaufrufe für Andes: 521063\n",
      "Seitenaufrufe für Anazarbus: 7764\n",
      "Seitenaufrufe für Anadyr (river): 3459\n",
      "Seitenaufrufe für Ambracia: 9280\n",
      "Seitenaufrufe für Abydos, Egypt: 95347\n",
      "Seitenaufrufe für Aberdeen: 437607\n",
      "Seitenaufrufe für Actium: 26777\n",
      "Seitenaufrufe für Abadan, Iran: 38464\n",
      "Seitenaufrufe für Adobe Inc.: 610329\n",
      "Seitenaufrufe für Austin, Texas: 1397545\n",
      "Seitenaufrufe für Crandall University: 13363\n",
      "Seitenaufrufe für Acadia University: 35829\n",
      "Seitenaufrufe für Annapolis Valley: 21087\n",
      "Seitenaufrufe für AFC Ajax: 1923325\n",
      "Seitenaufrufe für Area 51: 1727047\n",
      "Seitenaufrufe für Albion, Michigan: 15618\n",
      "Seitenaufrufe für Alicante: 294728\n",
      "Seitenaufrufe für Abadeh: 2905\n",
      "Seitenaufrufe für Abae: 2012\n",
      "Seitenaufrufe für Abakan: 35441\n",
      "Seitenaufrufe für Aswan: 141902\n",
      "Seitenaufrufe für Arapaoa Island: 3764\n",
      "Seitenaufrufe für Arbroath Abbey: 11023\n",
      "Seitenaufrufe für Abano Terme: 8786\n",
      "Seitenaufrufe für Aeclanum: 3796\n",
      "Seitenaufrufe für Aegadian Islands: 14511\n",
      "Seitenaufrufe für Ajaigarh: 6190\n",
      "Seitenaufrufe für Ajanta Caves: 763031\n",
      "Seitenaufrufe für Ajmer: 214305\n",
      "Seitenaufrufe für Afyonkarahisar: 42566\n",
      "Seitenaufrufe für Abdera, Spain: 2380\n",
      "Seitenaufrufe für Aberavon (UK Parliament constituency): 15272\n",
      "Seitenaufrufe für Abercarn: 3733\n",
      "Seitenaufrufe für Aberdour: 9624\n",
      "Seitenaufrufe für Abersychan: 3389\n",
      "Seitenaufrufe für Andalusia: 856236\n",
      "Seitenaufrufe für Azad Kashmir: 557995\n",
      "Seitenaufrufe für American Registry for Internet Numbers: 14885\n",
      "Seitenaufrufe für Akihabara: 182997\n",
      "Seitenaufrufe für Southeast Alaska: 38268\n",
      "Seitenaufrufe für Alcobaça, Portugal: 17021\n",
      "Seitenaufrufe für Amu Darya: 161061\n",
      "Seitenaufrufe für Alexandria, Indiana: 12554\n",
      "Seitenaufrufe für Alexandria, Louisiana: 72661\n",
      "Seitenaufrufe für Alexandria, Romania: 8874\n",
      "Seitenaufrufe für Andersonville, Georgia: 16766\n",
      "Seitenaufrufe für Agra Canal: 4149\n",
      "Seitenaufrufe für Amakusa: 6062\n",
      "Seitenaufrufe für Achiltibuie: 5398\n",
      "Seitenaufrufe für Azores: 1280140\n",
      "Seitenaufrufe für Outback: 210643\n",
      "Seitenaufrufe für Ansbach: 40577\n",
      "Seitenaufrufe für Aveiro, Portugal: 82830\n",
      "Seitenaufrufe für The Bronx: 807715\n",
      "Seitenaufrufe für Black Forest: 403831\n",
      "Seitenaufrufe für Bursa: 231581\n",
      "Seitenaufrufe für Baker Island: 138907\n",
      "Seitenaufrufe für Bassas da India: 18604\n",
      "Seitenaufrufe für British Virgin Islands: 681550\n",
      "Seitenaufrufe für Bosporus: 460620\n",
      "Seitenaufrufe für Byzantium: 300177\n",
      "Seitenaufrufe für British Isles: 483162\n",
      "Seitenaufrufe für Boron: 429708\n",
      "Seitenaufrufe für Brandenburg: 283493\n",
      "Seitenaufrufe für Bundestag: 495533\n",
      "Seitenaufrufe für Bank of Italy: 18148\n",
      "Seitenaufrufe für Bletchley Park: 298265\n",
      "Seitenaufrufe für Benelux: 346244\n",
      "Seitenaufrufe für Prince-Bishopric of Brandenburg: 2607\n",
      "Seitenaufrufe für Boone, North Carolina: 165278\n",
      "Seitenaufrufe für Bishkek: 296770\n",
      "Seitenaufrufe für Birka: 34417\n",
      "Seitenaufrufe für Balmoral Castle: 3039669\n",
      "Seitenaufrufe für Balsall Heath: 8785\n",
      "Seitenaufrufe für Bob Jones University: 171267\n",
      "Seitenaufrufe für International Bureau of Weights and Measures: 53878\n",
      "Seitenaufrufe für Bakassi: 32827\n",
      "Seitenaufrufe für Burwash Hall: 2158\n",
      "Seitenaufrufe für Bodmin: 28800\n",
      "Seitenaufrufe für Bamberg: 112880\n",
      "Seitenaufrufe für Bundaberg Rum: 31368\n",
      "Seitenaufrufe für Ben Nevis: 340933\n",
      "Seitenaufrufe für Belfast: 1037572\n",
      "Seitenaufrufe für Colorado: 1401061\n",
      "Seitenaufrufe für Cayman Islands: 1122472\n",
      "Seitenaufrufe für Chalmers University of Technology: 60283\n",
      "Seitenaufrufe für Cape Breton Island: 146668\n",
      "Seitenaufrufe für Council of the European Union: 185246\n",
      "Seitenaufrufe für Campaign for Real Ale: 25563\n",
      "Seitenaufrufe für Chernobyl: 722540\n",
      "Seitenaufrufe für CN Tower: 680440\n",
      "Seitenaufrufe für Colorado Springs, Colorado: 491487\n",
      "Seitenaufrufe für Cambridgeshire: 182816\n",
      "Seitenaufrufe für Cheddar, Somerset: 55734\n",
      "Seitenaufrufe für Chojnów: 3250\n",
      "Seitenaufrufe für Concord, New Hampshire: 123299\n",
      "Seitenaufrufe für County Dublin: 121220\n",
      "Seitenaufrufe für Crete: 923171\n",
      "Seitenaufrufe für Cyclades: 178519\n",
      "Seitenaufrufe für Cedar Falls, Iowa: 50871\n",
      "Seitenaufrufe für Columbia, Missouri: 153987\n",
      "Seitenaufrufe für Copacabana, Rio de Janeiro: 87996\n",
      "Seitenaufrufe für Chiapas: 236878\n",
      "Seitenaufrufe für Chrysler Building: 631834\n",
      "Seitenaufrufe für Columbus, Indiana: 87152\n",
      "Seitenaufrufe für Corinth: 218224\n",
      "Seitenaufrufe für Cotswolds: 597609\n",
      "Seitenaufrufe für Central Plaza (Hong Kong): 16235\n",
      "Seitenaufrufe für Cook Islands: 639281\n",
      "Seitenaufrufe für London Borough of Croydon: 85642\n",
      "Seitenaufrufe für Cholistan Desert: 55856\n",
      "Seitenaufrufe für The Maritimes: 121060\n",
      "Seitenaufrufe für Carson City, Nevada: 237239\n",
      "Seitenaufrufe für California Department of Transportation: 28358\n",
      "Seitenaufrufe für Caribbean Sea: 342918\n",
      "Seitenaufrufe für Concord, Michigan: 2131\n",
      "Seitenaufrufe für Delphi: 358109\n",
      "Seitenaufrufe für Devonian: 280627\n",
      "Seitenaufrufe für Dardanelles: 397434\n",
      "Seitenaufrufe für Daugava: 29411\n",
      "Seitenaufrufe für Delicate Arch: 49165\n",
      "Seitenaufrufe für Dejima: 98170\n",
      "Seitenaufrufe für Dayton, Ohio: 296041\n",
      "Seitenaufrufe für Deception Pass: 45176\n",
      "Seitenaufrufe für Dartmouth College: 706507\n",
      "Seitenaufrufe für Dartmouth, Devon: 49453\n",
      "Seitenaufrufe für Dar es Salaam: 440769\n",
      "Seitenaufrufe für Dublin: 1306032\n",
      "Seitenaufrufe für Denver: 1042964\n",
      "Seitenaufrufe für Dead Sea: 852790\n",
      "Seitenaufrufe für Davenport, Iowa: 139358\n",
      "Seitenaufrufe für Dalhousie University: 129502\n",
      "Seitenaufrufe für Ducati: 54793\n",
      "Seitenaufrufe für Deccan Traps: 176931\n",
      "Seitenaufrufe für Dahomey: 1018498\n",
      "Seitenaufrufe für Dundee: 304688\n",
      "Seitenaufrufe für London Docklands: 60787\n",
      "Seitenaufrufe für Detroit River: 63352\n",
      "Seitenaufrufe für Degree Confluence Project: 3384\n",
      "Seitenaufrufe für Dimona: 33709\n",
      "Seitenaufrufe für Davis, California: 113485\n",
      "Seitenaufrufe für Equatorial Guinea: 1120706\n",
      "Seitenaufrufe für Europa Island: 21443\n",
      "Seitenaufrufe für Helsingør: 60086\n",
      "Seitenaufrufe für Enniskillen: 95072\n",
      "Seitenaufrufe für European Free Trade Association: 179420\n",
      "Seitenaufrufe für East River: 122431\n",
      "Seitenaufrufe für Ellensburg, Washington: 74292\n",
      "Seitenaufrufe für Eindhoven University of Technology: 51745\n",
      "Seitenaufrufe für Empire State Building: 1422474\n",
      "Seitenaufrufe für Eureka, Missouri: 20898\n",
      "Seitenaufrufe für Eden Project: 143662\n",
      "Seitenaufrufe für European Commission: 358109\n",
      "Seitenaufrufe für Ebor, New South Wales: 3698\n",
      "Seitenaufrufe für European Space Operations Centre: 8221\n",
      "Seitenaufrufe für Fredericton: 115160\n",
      "Seitenaufrufe für French Polynesia: 797717\n",
      "Seitenaufrufe für French Southern and Antarctic Lands: 393126\n",
      "Seitenaufrufe für Fontainebleau: 122598\n",
      "Seitenaufrufe für FIFA: 3667587\n",
      "Seitenaufrufe für Finger Lakes: 229613\n",
      "Seitenaufrufe für Fort Wayne, Indiana: 224311\n",
      "Seitenaufrufe für Fenway Park: 334100\n",
      "Seitenaufrufe für Federated States of Micronesia: 534661\n",
      "Seitenaufrufe für Fairmount, Indiana: 17190\n",
      "Seitenaufrufe für Fort Collins, Colorado: 211743\n",
      "Seitenaufrufe für Fort William, Highland: 107274\n",
      "Seitenaufrufe für Fair Isle: 83631\n",
      "Seitenaufrufe für Florence: 999451\n",
      "Seitenaufrufe für French Foreign Legion: 931859\n",
      "Seitenaufrufe für Food and Drug Administration: 377156\n",
      "Seitenaufrufe für Gothenburg: 556417\n",
      "Seitenaufrufe für Global Positioning System: 876934\n",
      "Seitenaufrufe für Germany: 6436477\n",
      "Seitenaufrufe für Great Lakes: 988528\n",
      "Seitenaufrufe für Gabon: 893791\n",
      "Seitenaufrufe für Gaza Strip: 654687\n",
      "Seitenaufrufe für Glorioso Islands: 35081\n",
      "Seitenaufrufe für Gdańsk: 512566\n",
      "Seitenaufrufe für Göta Canal: 21435\n",
      "Seitenaufrufe für Guinea: 865629\n",
      "Seitenaufrufe für University of Gothenburg: 38338\n",
      "Seitenaufrufe für German Unity Day: 148584\n",
      "Seitenaufrufe für Ghent: 371005\n",
      "Seitenaufrufe für Ganges: 844073\n",
      "Seitenaufrufe für Geneva: 939826\n",
      "Seitenaufrufe für Geocaching: 254560\n",
      "Seitenaufrufe für Gestapo: 702426\n",
      "Seitenaufrufe für Goshen, Indiana: 52334\n",
      "Seitenaufrufe für Gilbert Plains: 2226\n",
      "Seitenaufrufe für Glasgow City Chambers: 11560\n",
      "Seitenaufrufe für East Germany: 1549341\n",
      "Seitenaufrufe für Granville, New South Wales: 14648\n",
      "Seitenaufrufe für Great Victoria Desert: 45239\n",
      "Seitenaufrufe für Gosford: 44127\n",
      "Seitenaufrufe für Geneva College: 20462\n",
      "Seitenaufrufe für Grinnell College: 149846\n",
      "Seitenaufrufe für Gavoi: 1351\n",
      "Seitenaufrufe für Hilter: 7377\n",
      "Seitenaufrufe für Hawaii: 2831507\n",
      "Seitenaufrufe für Holland: 855362\n",
      "Seitenaufrufe für Heard Island and McDonald Islands: 371577\n",
      "Seitenaufrufe für Holy See: 893177\n",
      "Seitenaufrufe für Heathrow Airport: 933239\n",
      "Seitenaufrufe für House of Lords: 1180489\n",
      "Seitenaufrufe für Hilversum: 64563\n",
      "Seitenaufrufe für Hobart: 329982\n",
      "Seitenaufrufe für Houston: 1355255\n",
      "Seitenaufrufe für Harvey Mudd College: 107229\n",
      "Seitenaufrufe für House of Commons of the United Kingdom: 1018962\n",
      "Seitenaufrufe für Hayling Island: 59805\n",
      "Seitenaufrufe für Honolulu: 723439\n",
      "Seitenaufrufe für Hanover, New Hampshire: 97624\n",
      "Seitenaufrufe für Hultsfred Municipality: 971\n",
      "Seitenaufrufe für Parliament of the United Kingdom: 790138\n",
      "Seitenaufrufe für Hawick: 38467\n",
      "Seitenaufrufe für Hatfield, Hertfordshire: 92844\n",
      "Seitenaufrufe für Hertfordshire: 519729\n",
      "Seitenaufrufe für Hook of Holland: 29517\n",
      "Seitenaufrufe für Harwich: 40569\n",
      "Seitenaufrufe für Harwich, Massachusetts: 11220\n",
      "Seitenaufrufe für Herat: 151269\n",
      "Seitenaufrufe für Harley-Davidson: 486316\n",
      "Seitenaufrufe für Harappa: 308872\n",
      "Seitenaufrufe für Heavy water: 572206\n",
      "Seitenaufrufe für Hamilton, Ontario: 416680\n",
      "Seitenaufrufe für Hamar: 45046\n",
      "Seitenaufrufe für Institut des Hautes Études Scientifiques: 16145\n",
      "Seitenaufrufe für Indian Ocean: 636732\n",
      "Seitenaufrufe für Iqaluit: 316701\n",
      "Seitenaufrufe für Iao Valley: 21845\n",
      "Seitenaufrufe für Idaho: 861369\n",
      "Seitenaufrufe für Isle of Man: 1796783\n",
      "Seitenaufrufe für IKEA: 1372395\n",
      "Seitenaufrufe für Iowa State University: 227006\n",
      "Seitenaufrufe für IIT Kanpur: 112369\n",
      "Seitenaufrufe für International Court of Justice: 665061\n",
      "Seitenaufrufe für International Atomic Energy Agency: 246625\n",
      "Seitenaufrufe für International Civil Aviation Organization: 238757\n",
      "Seitenaufrufe für Information Sciences Institute: 6006\n",
      "Seitenaufrufe für International Olympic Committee: 391789\n",
      "Seitenaufrufe für Islamabad Capital Territory: 107626\n",
      "Seitenaufrufe für Indus River: 697526\n",
      "Seitenaufrufe für Intelsat: 58411\n",
      "Seitenaufrufe für Geography of Japan: 161286\n",
      "Seitenaufrufe für Jersey: 1260509\n"
     ]
    }
   ],
   "source": [
    "cleaned_articles_with_clicks = []\n",
    "for article in cleaned_articles:\n",
    "    if 'title' in article:\n",
    "        article['clicks'] = get_wikipedia_pageviews_2022(article['title'])\n",
    "        print(f\"Seitenaufrufe für {article['title']}: {article['clicks']}\")\n",
    "    else:\n",
    "        article['clicks'] = None\n",
    "        print(f\"Keine Seitenaufrufe für diesen {article['title']} verfügbar.\")\n",
    "    cleaned_articles_with_clicks.append(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('articles_with_dates.json', 'w') as file:\n",
    "    json.dump(cleaned_articles, file, ensure_ascii=False,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in articles:\n",
    "    print(\n",
    "        article['title'], len(article['history']), len(article['sentencesWithDates']))\n",
    "    print('------------------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
